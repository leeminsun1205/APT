@inproceedings{radford2021learning,
  title        = {Learning transferable visual models from natural language supervision},
  author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle    = {International conference on machine learning},
  pages        = {8748--8763},
  year         = {2021},
  organization = {PMLR}
}

@inproceedings{madry2017towards,
  title     = {Towards deep learning models resistant to adversarial attacks},
  author    = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle = {International Conference on Learning Representations},
  year      = {2018}
}

@article{zhou2022learning,
  title     = {Learning to prompt for vision-language models},
  author    = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal   = {International Journal of Computer Vision},
  volume    = {130},
  number    = {9},
  pages     = {2337--2348},
  year      = {2022},
  publisher = {Springer}
}

@inproceedings{li2024apt,
  title     = {One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models},
  author    = {Lin Li and Haoyan Guan and Jianing Qiu and Michael Spratling},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024}
}

@inproceedings{goodfellow2014explaining,
  title     = {Explaining and harnessing adversarial examples},
  author    = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle = {International Conference on Learning Representations},
  year      = {2015}
}

@inproceedings{chen_visual_2023,
  title     = {Visual {Prompting} for {Adversarial} {Robustness}},
  author    = {Chen, Aochuan and Lorenz, Peter and Yao, Yuguang and Chen, Pin-Yu and Liu, Sijia},
  booktitle = {{ICASSP} 2023 - 2023 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
  year      = {2023},
  pages     = {1--5},
  doi       = {10.1109/ICASSP49357.2023.10097245}
}

@inproceedings{chen_adversarial_2020,
  title     = {Adversarial {Robustness}: {From} {Self}-{Supervised} {Pre}-{Training} to {Fine}-{Tuning}},
  author    = {Chen, Tianlong and Liu, Sijia and Chang, Shiyu and Cheng, Yu and Amini, Lisa and Wang, Zhangyang},
  booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
  year      = {2020},
  pages     = {699--708}
}

% ===== DATASET CITATIONS =====

% CIFAR-10 and CIFAR-100
@techreport{krizhevsky2009learning,
  title       = {Learning multiple layers of features from tiny images},
  author      = {Krizhevsky, Alex},
  institution = {University of Toronto},
  year        = {2009}
}

% TinyImageNet
@article{le2015tiny,
  title   = {Tiny ImageNet Visual Recognition Challenge},
  author  = {Le, Ya and Yang, Xuan},
  journal = {CS 231N},
  volume  = {7},
  number  = {7},
  pages   = {3},
  year    = {2015}
}

% ImageNet
@article{russakovsky2015imagenet,
  title     = {{ImageNet} Large Scale Visual Recognition Challenge},
  author    = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
  journal   = {International Journal of Computer Vision},
  volume    = {115},
  number    = {3},
  pages     = {211--252},
  year      = {2015},
  publisher = {Springer}
}

% CIFAR-10-C, CIFAR-100-C, ImageNet-C (Corruption benchmarks)
@inproceedings{hendrycks2019benchmarking,
  title     = {Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author    = {Hendrycks, Dan and Dietterich, Thomas},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}

% CIFAR-10.1
@article{recht2018cifar,
  title   = {Do {CIFAR}-10 Classifiers Generalize to {CIFAR}-10?},
  author  = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  journal = {arXiv preprint arXiv:1806.00451},
  year    = {2018}
}

% Caltech-101
@inproceedings{feifei2004learning,
  title     = {Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories},
  author    = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshop},
  pages     = {178--178},
  year      = {2004}
}

% Oxford Pets
@inproceedings{parkhi2012cats,
  title     = {Cats and Dogs},
  author    = {Parkhi, Omkar M. and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, C. V.},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {3498--3505},
  year      = {2012}
}

% Stanford Cars
@inproceedings{krause2013stanford,
  title     = {3D Object Representations for Fine-Grained Categorization},
  author    = {Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle = {IEEE International Conference on Computer Vision Workshops},
  pages     = {554--561},
  year      = {2013}
}

% Flowers-102
@inproceedings{nilsback2008automated,
  title     = {Automated Flower Classification over a Large Number of Classes},
  author    = {Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle = {Indian Conference on Computer Vision, Graphics and Image Processing},
  pages     = {722--729},
  year      = {2008}
}

% Food-101
@inproceedings{bossard2014food,
  title     = {Food-101 -- Mining Discriminative Components with Random Forests},
  author    = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle = {European Conference on Computer Vision},
  pages     = {446--461},
  year      = {2014}
}

% FGVC Aircraft
@article{maji2013aircraft,
  title   = {Fine-Grained Visual Classification of Aircraft},
  author  = {Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal = {arXiv preprint arXiv:1306.5151},
  year    = {2013}
}

% DTD (Describable Textures Dataset)
@inproceedings{cimpoi2014describing,
  title     = {Describing Textures in the Wild},
  author    = {Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {3606--3613},
  year      = {2014}
}

% EuroSAT
@article{helber2019eurosat,
  title     = {EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},
  author    = {Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal   = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume    = {12},
  number    = {7},
  pages     = {2217--2226},
  year      = {2019},
  publisher = {IEEE}
}

% UCF-101
@article{soomro2012ucf101,
  title   = {UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild},
  author  = {Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal = {arXiv preprint arXiv:1212.0402},
  year    = {2012}
}
