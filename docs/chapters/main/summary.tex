\chapter*{\centering\Large{Tóm tắt đồ án}}
\addcontentsline{toc}{chapter}{Tóm tắt đồ án}

Đồ án tập trung nghiên cứu và nâng cao tính bền vững (robustness) của các mô hình Đa phương thức Ngôn ngữ-Thị giác (Vision-Language Models - VLMs), cụ thể là mô hình CLIP, trước các tấn công đối kháng (adversarial attacks). Trong khi các hệ thống AI hiện đại ngày càng trở nên mạnh mẽ, sự nhạy cảm của chúng đối với những nhiễu loạn nhỏ không thể nhận thấy (adversarial perturbations) vẫn là một thách thức đáng kể cho việc triển khai thực tế.

Để giải quyết vấn đề này mà không gặp phải yêu cầu cao về tài nguyên tính toán của việc tinh chỉnh toàn bộ mô hình (full fine-tuning), chúng tôi triển khai phương pháp \textbf{Adversarial Prompt Tuning (APT)}. Phương pháp này giữ nguyên các trọng số của mô hình và chỉ tối ưu hóa các vector ngữ cảnh (context vectors) ở đầu vào văn bản thông qua một quy trình tối ưu hóa tối-đại-thiểu (min-max optimization). Một phát hiện then chốt được tích hợp vào đồ án là "chỉ cần một từ là đủ" (One-word is enough) - việc tối ưu hóa dù chỉ một token duy nhất cũng có thể mang lại khả năng phòng thủ mạnh mẽ, giúp tối ưu hóa đáng kể bộ nhớ và thời gian huấn luyện.

Bên cạnh đó, APT còn cho thấy khả năng cải thiện tính bền vững đa phương thức (Cross-modal robustness), giúp mô hình chống lại cả các cuộc tấn công trên nhánh văn bản dù chỉ được huấn luyện đối kháng trên nhánh hình ảnh. Kết quả thực nghiệm trên các bộ dữ liệu benchmark khẳng định APT đạt được sự cân bằng tối ưu giữa độ chính xác trên dữ liệu sạch và độ bền vững trước tấn công, đề xuất giải pháp hiệu quả cho việc phát triển các hệ thống VLM an toàn và tiết kiệm tài nguyên.