\chapter{Thực nghiệm \& Kết quả (Experiments)}
\label{chap:experiments}

Trong chương này, chúng tôi trình bày các kết quả thực nghiệm để đánh giá hiệu quả của phương pháp Adversarial Prompt Tuning (APT). Chúng tôi so sánh APT với các phương pháp Baseline phổ biến trên nhiều khía cạnh: độ chính xác trên dữ liệu sạch (Clean Accuracy), độ bền vững trước tấn công đối kháng (Robust Accuracy), khả năng tổng quát hóa sang các miền dữ liệu mới (Out-Of-Distribution), và hiệu quả khi dữ liệu khan hiếm (Few-shot Learning).

\section{Cấu hình thực nghiệm (Experimental Setup)}

\subsection{Bộ dữ liệu (Datasets)}
Hệ thống thực nghiệm được thực hiện trên benchmark toàn diện bao gồm 15 bộ dữ liệu thị giác thuộc nhiều lĩnh vực khác nhau, được chia thành hai nhóm chính để đánh giá khả năng của mô hình:
\begin{enumerate}
    \item \textbf{In-Distribution (ID):} Sử dụng để đánh giá hiệu năng trên cùng miền dữ liệu. Các bộ dữ liệu bao gồm:
          \begin{itemize}
              \item \textbf{CIFAR-10 \& CIFAR-100:} Bộ dữ liệu nhận dạng vật thể phổ biến.
              \item \textbf{TinyImageNet:} Phiên bản thu nhỏ của ImageNet với kích thước ảnh $64 \times 64$.
              \item \textbf{Food101, OxfordPets, StanfordCars, v.v.:} Các bộ dữ liệu chuyên biệt (fine-grained).
          \end{itemize}
    \item \textbf{Out-Of-Distribution (OOD):} Sử dụng để đánh giá khả năng chuyển giao (transferability) của prompt đã học được sang các biến thể dữ liệu chưa từng gặp. Ví dụ: Prompt được học trên ImageNet sẽ được kiểm thử trên ImageNet-V2, ImageNet-Sketch, ImageNet-A, ImageNet-R.
\end{enumerate}

\subsection{Cài đặt huấn luyện (Implementation Details)}
Tất cả các thí nghiệm được thực hiện với các thiết lập sau:
\begin{itemize}
    \item \textbf{Backbone:} Sử dụng kiến trúc \textbf{ViT-B/32} của CLIP.
    \item \textbf{Prompt:} Độ dài ngữ cảnh $M=16$. Khởi tạo ngẫu nhiên từ phân phối chuẩn $\mathcal{N}(0, 0.02)$. Vị trí token lớp: "end" (cuối prompt).
    \item \textbf{Adversarial Training:} Tấn công PGD được tích hợp trong quá trình train với budget $\epsilon=4/255$, số bước lặp $k=3$, và bước nhảy $\alpha=2/255$.
    \item \textbf{Optimizer:} Sử dụng SGD optimizer với learning rate khởi tạo $\lambda=0.002$, giảm dần theo Cosine Annealing scheduler.
    \item \textbf{Training Duration:} Huấn luyện trong 10 epochs (đối với chế độ few-shot) hoặc 50 epochs (đối với chế độ full-data).
\end{itemize}

\section{Kết quả chính (Main Results)}
Temp
\section{Đánh giá chuyên sâu (Ablation Study \& Analysis)}

\subsection{Hiệu quả dữ liệu (Few-shot Efficiency)}
Chúng tôi đánh giá hiệu năng của APT khi số lượng mẫu/lớp (shots) thay đổi: 1, 2, 4, 8, 16.
Kết quả cho thấy APT hội tụ rất nhanh. Chỉ với \textbf{1 shot} (1 ảnh cho mỗi lớp), APT đã có thể cải thiện Robustness đáng kể so với baseline. Hiệu năng tăng dần và bão hòa quanh mức 16 shots, chứng tỏ phương pháp không đòi hỏi lượng dữ liệu lớn như việc fine-tune toàn bộ mô hình.

\subsection{Khả năng tổng quát hóa OOD (OOD Generalization)}
Khi đưa mô hình đã học trên ImageNet sang kiểm thử trên các tập dữ liệu OOD (như ImageNet-Sketch - ảnh phác thảo), APT vẫn duy trì được độ chính xác cao hơn đáng kể so với CoOp. Điều này gợi ý rằng prompt học được bởi các phương pháp thông thường (CoOp) có xu hướng overfit vào các chi tiết bề mặt (texture, màu sắc) của tập train, trong khi prompt của APT (nhờ quá trình đối kháng) đã học được các khái niệm trừu tượng (hình dáng, cấu trúc) bất biến hơn.

\section{Kết luận chương}
Các thực nghiệm trên diện rộng đã khẳng định tính hiệu quả, bền vững và tối ưu về chi phí của phương pháp APT. Phương pháp này không chỉ đạt kết quả cao hơn các baseline về độ chính xác mà còn giải quyết bài toán độ bền vững mà không cần thay đổi cấu trúc mô hình.
