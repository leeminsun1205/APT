\chapter{Cơ sở lý thuyết \& Tổng quan (Background)}
\label{chap:background}

Để hiểu rõ phương pháp Adversarial Prompt Tuning (APT) được thực nghiệm trong đồ án này, chương này sẽ trình bày chi tiết các cơ sở lý thuyết nền tảng. Nội dung bao gồm kiến trúc và cơ chế hoạt động của mô hình CLIP, các khái niệm cơ bản về tấn công đối kháng (Adversarial Attacks) với trọng tâm là thuật toán PGD, và cuối cùng là tổng quan kỹ thuật Prompt Learning, cụ thể là phương pháp CoOp.

\section{Mô hình CLIP (Contrastive Language-Image Pre-training)}
CLIP (Contrastive Language-Image Pre-training) \cite{radford2021learning} là một mô hình học biểu diễn đa phương thức (multi-modal representation learning) tiên phong trong lĩnh vực, được OpenAI giới thiệu vào năm 2021. Khác biệt so với các phương pháp thị giác máy tính truyền thống vốn phụ thuộc vào các bộ dữ liệu được gán nhãn thủ công tốn kém (như ImageNet) và bị giới hạn trong một tập hợp các lớp cố định, CLIP học các khái niệm thị giác trực tiếp từ giám sát ngôn ngữ tự nhiên (natural language supervision). Cách tiếp cận này cho phép CLIP sở hữu khả năng "zero-shot", nghĩa là mô hình có thể phân loại các đối tượng chưa từng thấy trong quá trình huấn luyện mà không cần bất kỳ bước tinh chỉnh (fine-tuning) nào.

\subsection{Kiến trúc mô hình}
CLIP sử dụng kiến trúc hai tháp (two-tower architecture) với hai encoder riêng biệt xử lý song song hình ảnh và văn bản:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{graphics/chapter-1/chapter-1-clip-architecture.png}
    \caption{Kiến trúc tổng quan của mô hình CLIP (Nguồn: \cite{radford2021learning})}
    \label{fig:clip_architecture}
\end{figure}

\textbf{Image Encoder ($\mathcal{I}$)} chuyển đổi ảnh đầu vào $x$ thành vector đặc trưng $I_f \in \mathbb{R}^{d_{img}}$. Trong đồ án này, chúng tôi sử dụng \textbf{ViT-B/32}: ảnh được chia thành các patch $32 \times 32$, sau đó đưa vào Transformer Encoder, với token [CLASS] làm biểu diễn cuối cùng.

\textbf{Text Encoder ($\mathcal{T}$)} chuyển văn bản $t$ thành vector $T_f \in \mathbb{R}^{d_{txt}}$ thông qua Transformer (tương tự GPT-2), sử dụng token [EOS] làm biểu diễn đặc trưng.

Hai vector $I_f$ và $T_f$ được chiếu vào không gian embedding chung và chuẩn hóa L2:
\begin{align}
    I_e & = \frac{W_I \cdot I_f}{\|W_I \cdot I_f\|}, \quad
    T_e = \frac{W_T \cdot T_f}{\|W_T \cdot T_f\|}
\end{align}

\subsection{Cơ chế huấn luyện: Contrastive Learning}
CLIP sử dụng InfoNCE loss. Với batch gồm $N$ cặp $(x_i, t_i)$, mô hình tính ma trận độ tương đồng cosine $N \times N$ với $s_{ij} = I_{e,i} \cdot T_{e,j}$. Mục tiêu là tối đa hóa $N$ phần tử đường chéo (cặp đúng) và tối thiểu hóa $N^2 - N$ phần tử còn lại (cặp sai):

\begin{equation}
    \mathcal{L} = \frac{1}{2} (\mathcal{L}_{I \to T} + \mathcal{L}_{T \to I})
\end{equation}
với:
\begin{equation}
    \mathcal{L}_{I \to T} = - \frac{1}{N} \sum_{i=1}^N \log \frac{\exp(s_{ii} / \tau)}{\sum_{j=1}^N \exp(s_{ij} / \tau)}
\end{equation}

Tham số $\tau$ là hệ số nhiệt độ học được. Hàm loss này buộc mô hình học cấu trúc ngữ nghĩa chung giữa hình ảnh và ngôn ngữ.

\subsection{Dự đoán Zero-shot (Zero-shot Prediction)}
Sau khi được huấn luyện trước (pre-training) trên tập dữ liệu khổng lồ, CLIP có thể được ứng dụng trực tiếp cho các tác vụ phân loại mà không cần huấn luyện lại. Quy trình phân loại zero-shot cho một ảnh $x$ với $K$ lớp ứng viên $\{y_1, y_2, ..., y_K\}$ được thực hiện qua các bước liên kết chặt chẽ:

Đầu tiên, với mỗi tên lớp $y_i$, một câu mô tả (prompt) sẽ được tạo ra theo mẫu định sẵn, ví dụ: "a photo of a $\{y_i\}$". Các prompt này sau đó được đưa qua Text Encoder để tạo ra tập các vector đặc trưng văn bản $\{w_1, w_2, ..., w_K\}$, trong đó $w_i = \mathcal{T}(\text{"a photo of a } y_i \text{"})$. Đồng thời, ảnh đầu vào $x$ được đưa qua Image Encoder để lấy vector $z = \mathcal{I}(x)$.

Cuối cùng, xác suất để ảnh $x$ thuộc về lớp $y_i$ được tính toán bằng hàm Softmax dựa trên độ tương đồng Cosine giữa $z$ và các $w_i$:
\begin{equation}
    p(y_i | x) = \frac{\exp(\text{sim}(z, w_i) / \tau)}{\sum_{j=1}^K \exp(\text{sim}(z, w_j) / \tau)}
\end{equation}
Trong đó $\text{sim}(u, v)$ là độ tương đồng cosine và $\tau$ là tham số nhiệt độ đã được học.

\subsection{Dự đoán Few-shot (Few-shot Prediction)}
Mặc dù khả năng zero-shot của CLIP rất ấn tượng, hiệu suất có thể được cải thiện đáng kể nếu có thêm một lượng nhỏ dữ liệu huấn luyện (vài mẫu cho mỗi lớp - $K$-shot). Trong ngữ cảnh của Mô hình Ngôn ngữ-Thị giác (VLM), thích nghi few-shot thường được thực hiện theo hai hướng chính: \textbf{Linear Probe CLIP}, nơi toàn bộ encoder bị đóng băng và chỉ có bộ phân loại tuyến tính trên cùng được huấn luyện; và \textbf{Prompt Learning}, phương pháp tối ưu hóa đầu vào văn bản để mô hình "hiểu" rõ hơn về nhiệm vụ cụ thể. Đây là nền tảng của phương pháp CoOp và APT sẽ được thảo luận chi tiết sau.

\section{Tấn công đối kháng (Adversarial Attacks)}
Trong lĩnh vực học sâu, sự tồn tại của các mẫu đối kháng (adversarial examples) đặt ra một thách thức an ninh nghiêm trọng. Mẫu đối kháng $x_{adv}$ được tạo ra bằng cách cộng thêm một nhiễu loạn $\delta$ rất nhỏ vảo đầu vào gốc $x$. Dù sự thay đổi này thường không thể nhận biết bằng mắt thường, nó lại khiến mô hình $f$ đưa ra dự đoán sai lệch với độ tin cậy cao: $f(x_{adv}) \neq f(x)$.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{graphics/chapter-1/chapter-1-adversarial-example.png}
    \caption{Minh họa tấn công đối kháng: thêm nhiễu vào ảnh gấu trúc khiến mô hình nhận diện sai thành vượn (Nguồn: \cite{goodfellow2014explaining})}
    \label{fig:adversarial_example}
\end{figure}

\subsection{Mô hình đe dọa (Threat Models)}
Dựa trên mức độ hiểu biết của kẻ tấn công về mô hình mục tiêu, các cuộc tấn công được phân loại thành hai nhóm chính. \textbf{Tấn công hộp trắng (White-box Attack)} giả định kẻ tấn công có toàn quyền truy cập vào kiến trúc mô hình, tham số trọng số và gradient; đây là kịch bản giả định nguy hiểm nhất dùng để đánh giá giới hạn an toàn của hệ thống. Ngược lại, \textbf{Tấn công hộp đen (Black-box Attack)} chỉ cho phép kẻ tấn công truy vấn đầu ra (nhãn hoặc xác suất) mà không biết cấu trúc bên trong. Trong đồ án này, chúng tôi tập trung vào kịch bản tấn công hộp trắng, sử dụng thông tin gradient để tạo ra các mẫu đối kháng mạnh nhất nhằm kiểm thử khả năng phòng thủ của APT.

\subsection{Bài toán tối ưu hóa tấn công}
Mục tiêu của kẻ tấn công là tìm ra nhiễu loạn $\delta$ sao cho tối đa hóa hàm mất mát $\mathcal{L}$ của mô hình, đồng thời đảm bảo nhiễu này nằm trong giới hạn cho phép $\epsilon$. Bài toán được phát biểu dưới dạng tối ưu hóa có ràng buộc:
\begin{equation}
    \max_{\delta \in \mathcal{S}} \mathcal{L}(f_\theta(x + \delta), y)
\end{equation}
Trong đó $\mathcal{S} = \{ \delta : \|\delta\|_p \le \epsilon \}$ là tập hợp các nhiễu cho phép trong quả cầu $L_p$ bán kính $\epsilon$. Chuẩn $L_\infty$ (khoảng cách Chebyshev) là chuẩn phổ biến nhất trong các nghiên cứu về ảnh đối kháng, giúp giới hạn sự thay đổi tối đa trên từng điểm ảnh.
\section{Prompt Learning}
Prompt Learning là phương pháp thích nghi (adaptation) mới được đề xuất cho các mô hình ngôn ngữ lớn, thay đổi cách tiếp cận truyền thống bằng việc tối ưu hóa đầu vào thay vì tinh chỉnh toàn bộ tham số mô hình (fine-tuning).

\subsection{Prompt "Cứng" (Hard Prompt) vs Prompt "Mềm" (Soft Prompt)}
Có hai hướng tiếp cận chính trong Prompt Learning. \textbf{Hard Prompt} sử dụng các từ ngữ tự nhiên được thiết kế thủ công, ví dụ "a photo of a [CLASS]". Tuy nhiên, phương pháp này đòi hỏi chuyên gia ngôn ngữ và khó tối ưu hóa do không gian ngôn ngữ mang tính rời rạc. Để khắc phục, \textbf{Soft Prompt} thay thế các từ ngữ bằng các vector tham số liên tục (continuous vectors) có thể học được. Phương pháp này cho phép áp dụng gradient descent để tìm ra các vector tối ưu trực tiếp trong không gian embedding, mang lại sự linh hoạt cao hơn.

\subsection{CoOp (Context Optimization)}
CoOp \cite{zhou2022learning} là công trình tiên phong áp dụng Soft Prompt cho CLIP. Thay vì sử dụng câu mẫu cố định, CoOp định nghĩa prompt dưới dạng chuỗi các vector học được:
\begin{equation}
    t = [V]_1 [V]_2 ... [V]_M [CLASS]
\end{equation}
Trong đó $\{[V]_1, ..., [V]_M\}$ là các vector ngữ cảnh được khởi tạo ngẫu nhiên hoặc từ word embedding, và được huấn luyện trên tập dữ liệu few-shot. Mặc dù CoOp cải thiện đáng kể độ chính xác của CLIP, nghiên cứu này chưa xem xét đến khía cạnh bền vững (robustness) trước tấn công đối kháng - đây chính là vấn đề mà đồ án này (APT) tập trung giải quyết.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{graphics/chapter-1/chapter-1-CoOp.png}
    \caption{Cơ chế học ngữ cảnh (Context Optimization) của CoOp (Nguồn: \cite{zhou2022learning})}
    \label{fig:coop_architecture}
\end{figure}

