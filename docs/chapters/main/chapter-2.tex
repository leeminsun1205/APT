\chapter{Phương pháp nghiên cứu (Methodology)}
\label{chap:methodology}

Chương này trình bày chi tiết về phương pháp \textbf{Adversarial Prompt Tuning (APT)}, giải pháp trọng tâm của đồ án nhằm nâng cao tính bền vững cho các mô hình Ngôn ngữ-Thị giác (VLMs). Chúng tôi sẽ đi sâu vào kiến trúc tổng thể, cách thức biểu diễn tham số prompt (Prompt Parameterization), phân  tích các chiến lược ngữ cảnh, và chiến lược tối ưu hóa "On-the-fly" để huấn luyện các prompt này.

\section{Tổng quan kiến trúc (Overview)}
Mục tiêu cốt lõi của APT là tìm ra một prompt văn bản $P$ sao cho mô hình VLM có thể phân loại đúng hình ảnh đầu vào ngay cả khi nó bị tấn công bởi nhiễu đối kháng. Khác với các phương pháp Adversarial Training truyền thống thường yêu cầu cập nhật lại toàn bộ trọng số của mô hình (Model Fine-tuning), APT tiếp cận theo hướng hiệu quả hóa tham số (parameter-efficient).

Hệ thống được xây dựng dựa trên ba thành phần chính tương tác chặt chẽ với nhau. Đầu tiên là \textbf{Frozen Backbone}, sử dụng mô hình CLIP đã được huấn luyện trước làm nền tảng. Trọng số $\theta$ của cả Image Encoder ($\mathcal{I}$) và Text Encoder ($\mathcal{T}$) được giữ nguyên (đóng băng) hoàn toàn trong suốt quá trình huấn luyện, đảm bảo tận dụng được tri thức thị giác-ngôn ngữ phong phú mà CLIP đã học được từ 400 triệu cặp dữ liệu. Thành phần thứ hai là \textbf{Learnable Prompt}, một chuỗi các vector tham số liên tục $V$ được chèn vào trước tên của các lớp. Đây là thành phần duy nhất được phép cập nhật gradient, giúp giảm đáng kể chi phí tính toán so với việc fine-tune toàn bộ mô hình. Cuối cùng là module \textbf{Adversary (Kẻ tấn công)}, có nhiệm vụ sinh ra nhiễu đối kháng $\delta$ (thường sử dụng thuật toán PGD) để cộng vào ảnh đầu vào nhằm cực đại hóa hàm mất mát phân loại.

Quy trình huấn luyện diễn ra như một bài toán tối ưu hóa Min-Max (Min-Max optimization) giữa hai thành phần: Prompt cố gắng học các đặc trưng ngữ nghĩa bền vững để giảm thiểu sai số dự đoán, trong khi Adversary liên tục tìm kiếm các điểm yếu của Prompt hiện tại để tối đa hóa sai số đó.

\subsection{So sánh với các phương pháp thích nghi khác}
Để làm rõ vị trí và ưu điểm của APT trong bối cảnh các phương pháp thích nghi hiệu quả tham số (parameter-efficient adaptation), chúng tôi tiến hành so sánh kiến trúc với hai phương pháp đại diện cho hai hướng tiếp cận khác nhau: \textbf{Adversarial Visual Prompting (AVP)} \cite{chen_visual_2023} và \textbf{Partial Adversarial Fine-Tuning (PAFT)} \cite{chen_adversarial_2020}.

APT là một phương pháp dựa trên \textit{text prompting}, trong khi AVP thuộc nhóm \textit{visual prompting} và PAFT là biến thể đối kháng của \textit{linear probing}. Cả ba phương pháp đều chia sẻ cùng một đặc điểm quan trọng: giữ nguyên (freeze) trọng số của Image Encoder và Text Encoder đã được huấn luyện trước, chỉ tối ưu hóa một tập tham số nhỏ để thích nghi với tác vụ cụ thể.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{graphics/chapter-2/chapter-2-apt-vs-others.pdf}
    \caption{So sánh kiến trúc giữa APT và các phương pháp thích nghi đối kháng khác. Các thành phần có thể học (learnable parameters) được tô màu vàng. Lưu ý rằng PAFT loại bỏ hoàn toàn nhánh văn bản của CLIP (Nguồn: \cite{li2024apt})}
    \label{fig:arch_comparison}
\end{figure}

Như minh họa trong Hình \ref{fig:arch_comparison}, sự khác biệt chính giữa ba phương pháp nằm ở \textit{vị trí} và \textit{bản chất} của các tham số có thể học:

\textbf{APT (Adversarial Prompt Tuning)} can thiệp vào nhánh văn bản bằng cách học một chuỗi các vector ngữ cảnh liên tục (continuous context vectors) được nối với class embedding trước khi đưa vào Text Encoder. Các vector này, được ký hiệu là $[V]_1, [V]_2, ..., [V]_M$, tạo thành một "soft prompt" có thể tối ưu hóa thông qua gradient descent. Điểm mạnh của APT là tận dụng được khả năng biểu diễn ngữ nghĩa linh hoạt của không gian văn bản, đồng thời duy trì nguyên vẹn kiến trúc đa phương thức (multimodal architecture) của CLIP. Số lượng tham số cần học chỉ là $M \times D$ (với $M$ là độ dài ngữ cảnh và $D$ là số chiều embedding, thường là 512), cực kỳ nhỏ so với tổng số tham số của mô hình.

\textbf{AVP (Adversarial Visual Prompting)} thay vào đó can thiệp vào nhánh hình ảnh bằng cách học một "visual prompt" --- một mẫu nhiễu có cấu trúc (structured perturbation) được cộng trực tiếp vào ảnh đầu vào trước khi đưa vào Image Encoder. Mẫu nhiễu này có cùng kích thước với ảnh đầu vào và được tối ưu hóa để cải thiện độ bền vững. Tuy nhiên, hạn chế của AVP là việc thay đổi trực tiếp pixel ảnh có thể làm giảm chất lượng đặc trưng tự nhiên (natural features) mà mô hình đã học được trong quá trình pre-training. Hơn nữa, số lượng tham số cần lưu trữ tương đương với kích thước ảnh đầu vào (ví dụ: $224 \times 224 \times 3$ cho ảnh RGB), lớn hơn đáng kể so với APT.

\textbf{PAFT (Partial Adversarial Fine-Tuning)} có cách tiếp cận khác biệt hoàn toàn: nó loại bỏ toàn bộ nhánh Text Encoder và chỉ giữ lại Image Encoder. Thay vì sử dụng độ tương đồng cosine giữa đặc trưng ảnh và văn bản, PAFT gắn thêm một lớp tuyến tính (linear layer) vào cuối Image Encoder để ánh xạ trực tiếp từ không gian đặc trưng hình ảnh sang không gian nhãn lớp. Lớp tuyến tính này, với trọng số có kích thước $[D, K]$ (với $K$ là số lớp), là thành phần duy nhất được huấn luyện thông qua adversarial training. Mặc dù PAFT có thể đạt được độ bền vững cao trên tập dữ liệu huấn luyện, nó mất đi một ưu điểm cốt lõi của CLIP: khả năng zero-shot và khả năng tổng quát hóa sang các lớp mới chưa từng thấy (unseen classes). Điều này là do lớp tuyến tính được mã hóa cứng (hard-coded) với số lượng lớp cố định trong tập huấn luyện, không thể mở rộng cho các lớp mới mà không cần huấn luyện lại.

Tóm lại, APT nổi bật với ba lợi thế chiến lược: (1) \textit{Hiệu quả tham số cao nhất} với số lượng tham số tối thiểu; (2) \textit{Bảo toàn kiến trúc đa phương thức} của CLIP, cho phép tận dụng cả thông tin hình ảnh và văn bản; (3) \textit{Khả năng tổng quát hóa linh hoạt} sang các lớp mới và các miền dữ liệu khác nhau nhờ vào việc duy trì cơ chế text-image alignment ban đầu của CLIP.

\section{Biểu diễn Prompt (Prompt Parameterization)}
Trong CLIP tiêu chuẩn, prompt thường được xây dựng từ các khuôn mẫu cứng nhắc (hard prompts) như "a photo of a [CLASS]". Phương pháp APT thay thế cách tiếp cận rời rạc này bằng các vector mềm (soft vectors) trong không gian liên tục, cho phép tối ưu hóa mượt mà hơn thông qua lan truyền ngược.

\subsection{Cấu trúc Soft Prompt}
Một prompt $t_k$ tương ứng với lớp thứ $k$ ($CLASS_k$) được định nghĩa toán học như một chuỗi nối tiếp các vector embedding. Cụ thể:
\begin{equation}
    t_k = [V]_1 [V]_2 ... [V]_M [CLASS]_k
\end{equation}
Trong công thức này, $M$ biểu thị độ dài của ngữ cảnh (context length), ví dụ $M=16$. Tập hợp $\{[V]_1, [V]_2, ..., [V]_M\}$ bao gồm các vector ngữ cảnh có cùng số chiều $D$ với không gian word embedding của CLIP (ví dụ $D=512$ cho kiến trúc ViT-B/32). Phần tử cuối cùng $[CLASS]_k$ là word embedding cố định tương ứng với tên của lớp thứ $k$. Việc chuyển sang không gian vector liên tục giúp mô hình tìm ra các biểu diễn ngữ nghĩa tối ưu mà ngôn ngữ tự nhiên khó có thể diễn đạt được.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{graphics/chapter-2/chapter-2-algo-overview.pdf}
    \caption{Minh họa cấu trúc Soft Prompt và cách chèn vào nhánh văn bản của CLIP (Nguồn: \cite{li2024apt})}
    \label{fig:apt_overview}
\end{figure}

\subsection{Biến thể: Class-Specific Context (CSC)}
Một biến thể phức tạp hơn của biểu diễn prompt là \textbf{Class-Specific Context (CSC)}. Trong cấu hình này, mỗi lớp $k$ sở hữu một tập vector ngữ cảnh riêng biệt $\{[V]_{m,k}\}_{m=1}^M$, hoàn toàn độc lập với các lớp khác. Khi đó, prompt cho lớp $k$ sẽ có dạng:
\begin{equation}
    t_k = [V]_{1,k} [V]_{2,k} ... [V]_{M,k} [CLASS]_k
\end{equation}
Ưu điểm của CSC là khả năng tùy biến cao; các vector ngữ cảnh được tối ưu hóa riêng biệt cho từng lớp, cho phép mô hình nắm bắt được các sắc thái ngữ nghĩa đặc thù. Tuy nhiên, hạn chế nghiêm trọng là sự bùng nổ về số lượng tham số cần học, tăng tuyến tính theo số lượng lớp ($K \times M \times D$). Điều này không chỉ gây tốn kém tài nguyên mà còn dễ dẫn đến hiện tượng quá khớp (overfitting) khi dữ liệu huấn luyện hạn chế.

\subsection{Chiến lược Unified Context (UC)}
Trong khuôn khổ đồ án này, chúng tôi ưu tiên sử dụng chiến lược \textbf{Unified Context (UC)}. Khác với CSC, UC áp dụng một ràng buộc chia sẻ trọng số: tất cả $K$ lớp trong tập dữ liệu đều sử dụng chung một tập hợp vector ngữ cảnh $\{[V]_m\}_{m=1}^M$. Điều này có nghĩa là các vector $[V]$ mang tính chất độc lập với lớp (class-agnostic).

Sự lựa chọn này được củng cố bởi hai lợi ích chiến lược. Thứ nhất là \textbf{Hiệu quả tham số (Parameter Efficiency)}. Một phát hiện quan trọng trong nghiên cứu của Li và cộng sự \cite{li2024apt} là "chỉ cần một từ là đủ" (One Word is Enough) --- nghĩa là việc tối ưu hóa dù chỉ một token duy nhất ($M=1$) cũng đã đủ để mang lại sự cải thiện đáng kể về độ bền vững. Điều này chứng minh rằng không gian prompt là một giao diện cực kỳ nhạy cảm và mạnh mẽ để điều khiển hành vi của VLM. Với UC, số lượng tham số cần tối ưu chỉ còn là $M \times D$, hoàn toàn độc lập với số lượng lớp $K$. Điều này đặc biệt quan trọng khi mở rộng phương pháp cho các tập dữ liệu quy mô lớn như ImageNet (1000 lớp), giúp tiết kiệm đáng kể bộ nhớ GPU. Thứ hai là khả năng \textbf{Tổng quát hóa bền vững (Robust Generalization)}. Với số lượng tham số ít hơn, mô hình bị buộc phải học các mẫu ngữ cảnh chung nhất, tránh việc "ghi nhớ" (memorization) các nhiễu đối kháng cục bộ của từng lớp. Kết quả thực nghiệm từ các nghiên cứu trước \cite{li2024apt} cũng chỉ ra rằng UC hoạt động vượt trội hơn CSC trong các kịch bản few-shot và chuyển giao miền (domain transfer).

\section{Độ đo đánh giá (Evaluation Metrics)}
Để đánh giá hiệu quả của phương pháp APT, chúng tôi sử dụng ba nhóm chỉ số cốt lõi nhằm đo lường cả hiệu năng phân loại, độ bền vững đối kháng và tính hiệu quả về mặt tài nguyên.

\subsection{Độ chính xác (Accuracy)}
Đây là các chỉ số đánh giá khả năng phân loại của mô hình trên các tập dữ liệu khác nhau:
\begin{itemize}
    \item \textbf{Clean Accuracy ($Acc_{clean}$):} Độ chính xác trung bình của mô hình trên tập dữ liệu ảnh sạch (không bị can thiệp bởi nhiễu đối kháng). Chỉ số này đo lường khả năng học và giữ vững các đặc trưng ngữ nghĩa tự nhiên của mô hình sau quá trình tuning.
    \item \textbf{Robust Accuracy ($Acc_{robust}$):} Độ chính xác của mô hình khi phải đối mặt với các mẫu ảnh đối kháng được sinh ra bởi thuật toán PGD với ngân sách nhiễu $\epsilon$. Đây là chỉ số quan trọng nhất để đánh giá khả năng phòng thủ của APT.
\end{itemize}

% \subsection{Chỉ số về Độ bền vững (Robustness Gap)}
% Nhằm đánh giá mức độ nhạy cảm của mô hình đối với nhiễu, chúng tôi xem xét \textbf{Accuracy Drop ($\Delta$)}:
% \begin{equation}
%     \Delta = Acc_{clean} - Acc_{robust}
% \end{equation}
% Giá trị $\Delta$ càng nhỏ chứng tỏ mô hình càng có độ ổn định cao, nghĩa là tính bền vững của nó không phụ thuộc quá nhiều vào sự hiện diện của nhiễu đối kháng.

\section{Chiến lược tối ưu hóa (Optimization Strategy)}
Bài toán tìm kiếm prompt tối ưu trong APT thực chất là một bài toán tối ưu hóa bền vững (robust optimization), được mô hình hóa dưới dạng bài toán Min-Max (Saddle Point Problem):
\begin{equation}
    \min_{P} \mathbb{E}_{(x, y) \in \mathcal{D}} \left[ \max_{\|\delta\|_\infty \leq \epsilon} \mathcal{L}(P, x + \delta, y) \right]
\end{equation}
Mục tiêu là tìm tập tham số prompt $P = \{[V]_1, ..., [V]_M\}$ sao cho cực tiểu hóa hàm mất mát kỳ vọng, trong khi nhiễu đối kháng $\delta$ (bị giới hạn trong quả cầu chuẩn $\epsilon$) luôn cố gắng cực đại hóa hàm mất mát đó.

\subsection{Hàm mất mát (Loss Function)}
Hàm mất mát $\mathcal{L}$ được sử dụng là Cross-Entropy tiêu chuẩn, tính toán dựa trên phân phối xác suất được dự đoán bởi mô hình CLIP. Với một ảnh đối kháng $x_{adv} = x + \delta$, xác suất để ảnh này thuộc về lớp $y$ được tính bằng hàm Softmax trên độ tương đồng cosine:
\begin{equation}
    p(y | x_{adv}, P) = \frac{\exp(\text{sim}(\mathcal{I}(x_{adv}), \mathcal{T}(t_y)) / \tau)}{\sum_{k=1}^K \exp(\text{sim}(\mathcal{I}(x_{adv}), \mathcal{T}(t_k)) / \tau)}
\end{equation}
Về mặt trực giác, các soft prompt đã học đóng vai trò như các "điểm neo" (anchors) vững chắc trong không gian biểu diễn chung (joint embedding space). Khi ảnh bị nhiễu tấn công và bị đẩy ra xa khỏi vùng biểu diễn sạch, các prompt này giúp căn chỉnh lại (realignment) vector đặc trưng hình ảnh với các khái niệm văn bản chính xác, từ đó duy trì độ chính xác dự đoán.
Từ đó, giá trị hàm mất mát để cập nhật prompt là:
\begin{equation}
    \mathcal{L}(P, x_{adv}, y) = -\log p(y | x_{adv}, P)
\end{equation}

\subsection{Lựa chọn Prompt cho Tấn công (Attack Prompt Selection)}
Một vấn đề tinh tế nhưng quan trọng trong quá trình huấn luyện là việc lựa chọn prompt nào để sinh ra nhiễu đối kháng $\delta$ trong vòng lặp tối đa hóa (Inner Maximization). Chúng tôi đã phân tích ba chiến lược tiềm năng:

Chiến lược đầu tiên, \textbf{Constant Strategy}, sử dụng một prompt cố định (ví dụ: "a photo of a [CLASS]") để sinh nhiễu trong suốt quá trình huấn luyện. Mặc dù phương pháp này có ưu điểm về tốc độ do có thể tái sử dụng các tính toán, nhiễu sinh ra thường không đủ mạnh vì nó không nhắm vào prompt $P$ đang thay đổi. Kết quả là tạo ra một "mục tiêu tĩnh" (static target), khiến prompt học được không đủ độ bền vững.

Chiến lược thứ hai, \textbf{Perturbed Strategy}, thực hiện tấn công đa phương thức bằng cách tối ưu hóa đồng thời cả nhiễu ảnh và nhiễu trên prompt (Multimodal Attack). Về lý thuyết, cách này tạo ra mẫu đối kháng cực đại, nhưng cái giá phải trả là chi phí tính toán khổng lồ do phải lan truyền ngược (backpropagation) qua cả nhánh Text Encoder trong mỗi bước tấn công.

Chiến lược thứ ba, và cũng là đề xuất của chúng tôi, là \textbf{On-the-fly Strategy}. Trong phương pháp này, nhiễu đối kháng được sinh ra dựa trên chính prompt $P$ đang được huấn luyện tại bước hiện tại:
\begin{equation}
    \delta^* = \arg \max_{\|\delta\|_\infty \leq \epsilon} \mathcal{L}(P_{\text{current}}, x + \delta, y)
\end{equation}
Chiến lược này tạo ra một "mục tiêu động" (dynamic target): khi prompt trở nên tốt hơn, nhiễu đối kháng cũng trở nên tinh vi hơn để "đánh lừa" chính prompt đó. Sự cùng tiến hóa (co-evolution) này buộc mô hình phải liên tục thích nghi, dẫn đến khả năng phòng thủ vượt trội trước các kiểu tấn công thích nghi (adaptive attacks) mà không làm tăng chi phí tính toán quá mức như trường hợp Perturbed Strategy. Rationale đằng sau việc sử dụng On-the-fly là để đảm bảo prompt luôn được thử thách bởi những mẫu đối kháng "khó" nhất tương ứng với trạng thái hiện tại của nó.

\subsection{Thuật toán huấn luyện tổng thể}
Dựa trên chiến lược On-the-fly, thuật toán huấn luyện APT được thiết kế để thực hiện xen kẽ giữa việc sinh ảnh đối kháng và cập nhật tham số prompt. Thay vì sử dụng một tập dữ liệu đối kháng cố định (offline), chúng tôi sinh nhiễu trực tiếp (online) trong mỗi batch, đảm bảo tính đa dạng và độ khó cao nhất của dữ liệu huấn luyện. Chi tiết thuật toán được trình bày trong Algorithm \ref{alg:apt}.

\begin{algorithm}[H]
    \caption{Adversarial Prompt Tuning (APT)}
    \label{alg:apt}
    \begin{algorithmic}[1]
        \Require Pre-trained CLIP ($\mathcal{I}, \mathcal{T}$), Training set $\mathcal{D}$, Budget $\epsilon$, Steps $T$, Meta-steps $S$.
        \Ensure Learned Prompt $P$.
        \State Khởi tạo $P$ ngẫu nhiên hoặc từ prompt thủ công.
        \For{each epoch}
        \For{each batch $(x, y) \in \mathcal{D}$}
        \State \textbf{// Bước 1: Sinh ảnh đối kháng (Inner Maximization)}
        \State Khởi tạo nhiễu ngẫu nhiên: $\delta \sim \mathcal{U}(-\epsilon, \epsilon)$
        \For{$t = 1$ to $T$}
        \State Tính toán gradient theo đầu vào: $g_{adv} = \nabla_{x+\delta} \mathcal{L}(P, x+\delta, y)$
        \State Cập nhật nhiễu: $\delta \leftarrow \text{clip}_{[-\epsilon, \epsilon]} (\delta + \alpha \cdot \text{sign}(g_{adv}))$
        \EndFor
        \State $x_{adv} = \text{clip}_{[0, 1]}(x + \delta)$
        \State
        \State \textbf{// Bước 2: Cập nhật Prompt (Outer Minimization)}
        \State Tính toán loss với ảnh đối kháng: $L = \mathcal{L}(P, x_{adv}, y)$
        \State Tính gradient theo prompt: $g_{prompt} = \nabla_P L$
        \State Cập nhật prompt (SGD): $P \leftarrow P - \eta \cdot g_{prompt}$
        \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

Quá trình tối ưu hóa hai cấp độ này (Bi-level Optimization) đảm bảo sự hội tụ về một điểm cân bằng Nash, nơi prompt học được khả năng trích xuất các đặc trưng ngữ nghĩa bất biến (invariant features) bất chấp sự hiện diện của nhiễu.

\section{Các đặc tính nâng cao của APT}

\subsection{Tính bền vững đa phương thức (Cross-modal Robustness)}
Một trong những ưu điểm vượt trội của APT được phát hiện trong \cite{li2024apt} là tính bền vững đa phương thức. Mặc dù quá trình huấn luyện đối kháng chỉ thực hiện trên nhánh hình ảnh (Visual Adversarial Training), các prompt được học lại cho thấy khả năng phòng thủ có được một cách gián tiếp đối với cả các cuộc tấn công trên nhánh văn bản (Textual Adversarial Attacks). Điều này cho thấy APT thực sự cải thiện khả năng căn chỉnh ngữ nghĩa cốt lõi của VLM, thay vì chỉ học các đặc trưng hình ảnh cục bộ.

\subsection{So sánh với Adversarial Visual Prompting (AVP)}
So với các phương pháp Adversarial Visual Prompting (vốn can thiệp vào các pixel của ảnh đầu vào), APT sở hữu những lợi thế rõ rệt. Thứ nhất, việc thay đổi "hướng dẫn" (instructions) ở phía văn bản mang tính ổn định hơn và ít làm giảm chất lượng đặc trưng tự nhiên của mô hình. Thứ hai, APT hiệu quả hơn về mặt lưu trữ và tính toán khi chỉ cần lưu một vài vector prompt nhỏ thay vì một template nhiễu có kích thước bằng ảnh đầu vào. Cuối cùng, APT tận dụng được bản chất của VLM là một mô hình dựa trên ngôn ngữ, biến giao diện văn bản thành một cơ chế phòng vệ linh hoạt.

