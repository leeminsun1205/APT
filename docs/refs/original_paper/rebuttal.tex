\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{bm}

\usepackage{tabularray}
% Import additional packages in the preamble file, before hyperref
\input{preamble}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\usepackage{hyperref}

% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
%\setcounter{figure}{2}
%\setcounter{table}{1}
%\setcounter{equation}{2}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter for `enumiv' to
% the number of references you have in the main paper (here, 6).
%\let\oldthebibliography=\thebibliography
%\let\oldendthebibliography=\endthebibliography
%\renewenvironment{thebibliography}[1]{%
%     \oldthebibliography{#1}%
%     \setcounter{enumiv}{6}%
%}{\oldendthebibliography}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{7387} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2023}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
% \title{\LaTeX\ Guidelines for Author Response}  % **** Enter the paper title here

% \maketitle
\thispagestyle{empty}
% \appendix

% Please add the following required packages to your document preamble:
% \usepackage{multirow}



%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
\paragraph{R-jo4n W1: Comparison with TeCoA.}
We follow the evaluation protocol of TeCoA to compare APT against it on zero-shot adversarial robustness in \cref{zero-shot}.
APT improves zero-shot accuracy and robustness over TeCoA by 1.1\% and 1.7\% on average, and 
consistently achieves higher robustness compared to TeCoA for each individual dataset.

% Note originally proposed for zero-shot and no few-shot performance and no code is provided.


% The effectiveness of APT compared to TeCoA lies in its parameter-efficiency and complementary performance. 
% First, taking an example of training a ViT-B/32, TeCoA uses about 85M parameters while APT uses only $512\times M$ parameters ($M$ is the number of context vectors). 


% Note that TeCoA and APT optimize different dimensions, model weight and text prompt respectively, to improve adversarial robustness so they are complementary instead of exclusive to each other.


\renewcommand*{\thetable}{R\arabic{table}}    
\begin{table}[tbp]
\centering
\caption{Zero-shot performance. 
All methods were trained on ImageNet.
Both AVP and APT were tuned with 100 shots.
The context length, $M$, of APT is 1.
``Average'' averages the results over 10 non-ImageNet datasets.
PAFT and APT-CSC are not included below since they are not applicable to the zero-shot setting.}
\vspace{-3mm}
\label{zero-shot}
\resizebox{\linewidth}{!}{%
\begin{tabular}{llllllllllllll} \toprule
&        & \multicolumn{11}{c} {Zero-shot Results}                 &         \\ \cline{4-14} 
& Method & \rotatebox{90}{ImageNet} & \rotatebox{90}{FGVC} & \rotatebox{90}{EuroSAT} & \rotatebox{90}{Caltech101} & \rotatebox{90}{StandforCars} & \rotatebox{90}{Food101} & \rotatebox{90}{OxfordPets} & \rotatebox{90}{Flowers102} & \rotatebox{90}{DTD}  & \rotatebox{90}{SUN397} & \rotatebox{90}{UCF101} & 
\rotatebox{90}{Average} \\ \hline
\multirow{5}{*}{Acc.}   & TeCoA  & 39.6     & 6.5  & 16.4    & 77.4       & 10.3         & 20.3    & 60.9       & \textbf{31.4}       & 23.7 & 32.0   & 35.4   & 31.4    \\
& + HEP  & 39.9     & 7.0  & \textbf{20.3}    & 77.4       & 10.3         & 21.7    & 61.5       & 30.5       & \textbf{26.3} & 32.0   & \textbf{36.2}   & 32.3    \\
& + AVP    & 39.5     & 6.5  & 16.3    & 77.3       & 10.4         & 20.2    & 60.9       & 31.3       & 23.4 & 32.0   & 35.4   & 31.4    \\
% & Ours original   & \textbf{40.3}     & 5.6  & 14.8    & \textbf{78.5}       & \textbf{12.8}         & \textbf{23.9}    & 63.9       & 30.9       & 22.5 & 32.6   & 34.7   & 32.0    \\
& + APT-UC   & \textbf{40.3}     & \textbf{7.1}  & 16.9    & \textbf{78.3}       & \textbf{12.1}         & \textbf{23.9}    & \textbf{65.2}       & 29.1       & 24.3 & \textbf{32.8}   & 35.5   & \textbf{32.5}    \\ \hline
\multirow{5}{*}{Rob.} & TeCoA  & 10.3     & 0.4  & 11.0     & 42.8       & 0.9          & 3.1     & 14.6       & 9.2        & 10.4 & 5.9    & 5.8    & 10.4    \\
& + HEP    & 10.3     & 0.5  & 9.2    & 42.8       & 0.9          & 3.2     & 14.3       & 8.8        & \textbf{11.6} & 5.9    & 6.2    & 10.3   \\
& + AVP    & 11.3     & 0.6  & \textbf{11.2}    & 45.1       & 1.1          & 3.4     & 16.4       & 9.8        & 11.0 & 6.6    & 6.6    & 11.2    \\
% & Ours original  & \textbf{12.2}     & \textbf{0.8}  & 11.1    & \textbf{45.8}  & \textbf{1.7}  & \textbf{3.8} & 19.9  & \textbf{10.3} & 10.9 & 6.9  & 7.2    & 11.8   \\ 
& + APT-UC   & \textbf{12.2}     & \textbf{0.8}  & \textbf{11.2}    & \textbf{45.7}      & \textbf{1.5}  & \textbf{3.8}    & \textbf{21.9}   & \textbf{10.0}       & \textbf{11.6} & \textbf{7.4}   & \textbf{7.5}   & \textbf{12.1}   \\
\bottomrule
\end{tabular}
}
\vspace{-3.5mm}
\end{table}

\vspace{-3.5mm}
\paragraph{R-jo4n W2: Zero-shot results.} We did perform zero-shot evaluation in the original text: results are given in Table 2 (``CrossDatasets'' column).
% We will improve the presentation of this part in the paper to reduce the confusion. 
In \cref{zero-shot}, we provide detailed results on each dataset and improved results for AVP and APT found by further hyperparameter optimization (the results in the original text Table 2 were optimized for OOD instead of zero-shot performance). 
APT achieves the highest zero-shot accuracy and robustness among all competitive methods.
We will revise the manuscript to add the new results and improve the presentation of zero-shot performance.

\vspace{-3.5mm}
\paragraph{R-Z2fn W1 \& W4: Add the pre-training discussion and the ablation study to the text from appendix.}
They were discussed in appendix C6 and C3 respectively. We will revise the paper to move them to the main text.

\vspace{-3.5mm}
\paragraph{R-Z2fn W2: Zero-shot results.}
Please see R-jo4n W2.

\vspace{-3.5mm}
\paragraph{R-Z2fn W3: The robust accuracy of 4-shot to 16-shot is reduced in the AVP method at $\epsilon=1/255$.}
This may be related to the ineffectiveness of AVP in few-shot setting as indicated by the poor performance gain from 1-shot to 16-shot at $\epsilon=4/255$.
Note that AVP is neither proposed by us nor based on text prompt so studying the above issue is beyond the scope of this work.

\vspace{-3.5mm}
\paragraph{R-Z2fn W5: result in Figure 6 where the decrese in accuracy exceeds the increase in robustness?}
The relatively worse trade-off in those datasets is likely related to their specific data distribution because the trade-off between accuracy and robustness is an inherent trait of the data distribution \citep{tsipras_robustness_2019}.
On the other hand, trade-off can be improved by, e.g., replacing the naive cross-entropy loss in the current APT with TRADES \citep{zhang_theoretically_2019} or any other advanced methods. 

\vspace{-3.5mm}
\paragraph{R-xgZ6 W1: Lack of novelty.}
While text prompting has been explored for clean generalization, it has never previously been studied for adversarial robustness of VLMs. 
This work is, therefore, novel in the following respects:
\begin{enumerate}
    \item it is the first work revealing the significant influence of text prompts on adversarial attack and defense on VLMs
    \item it proposes the first text prompt tuning method for improving adversarial robustness on VLMs.
    \item it paves a new way for new methods for enhancing adversarial robustness that are complementary to model training and visual prompting.
\end{enumerate}
Related works about text prompting were given in Section 2, but we will add more details to the revised paper. 

\vspace{-3.5mm}
\paragraph{R-xgZ6 W2: The update of context v, also being applied if we use the constant strategy?}
Yes. 
The prompt for inference, $\bm{t}$, and the prompt for attack, $\bm{t}'$, are independent to each other. 
Only $\bm{t}'$ is fixed for generating training adversarial examples (Algorithm 1). 
The context $\bm{v}$ inside $\bm{t}$ is updated based on the loss calculated on the training adversarial examples (Line 12-13 in Algorithm 2). 

\vspace{-3.5mm}
\paragraph{R-xgZ6 W3: Does the prompt tuning consider tuning the context of 't' on top of the jointly perturbed prompts ($\bm{\delta}'$) generated from perturbed setting?}
No.
$\bm{\delta}'$ is only applied to the prompt for attack, $\bm{t}'$, for generating training adversarial examples. 
$\bm{\delta}'$ has been never applied to the prompt for inference, $\bm{t}$.

\vspace{-3.5mm}
\paragraph{R-xgZ6 W4: What if the attacker tune an additional unified context on the evaluation set?}
That will further enlarge adversarial loss and thus increase the chance of misclassification.
Nevertheless, our method is expected to still work by, e.g., neutralizing the adversarial effect of text perturbation.
Note that attacking text prompt is beyond the scope of this work since we adopt the common threat model \citep{zhao_evaluating_2023} where attackers can only manipulate images.

\vspace{-3.5mm}
\paragraph{R-xgZ6 W5: Can the method combine with AVP and further improve the robustness?}
Yes.  
To combine APT with AVP, we first tune the model by APT and then apply AVP to the APT-tuned model.
In \cref{tab: apt plust avp}, their combination achieves a higher robustness than any of them individually. 

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}

\begin{table}[t]
\centering
\caption{The average performance over 11 datasets for combining APT with AVP. The number of shots is ``All''.}
\vspace{-3mm}
\label{tab: apt plust avp}
\resizebox{0.6\linewidth}{!}{%
\begin{tabular}{@{}lcc@{}}
\toprule
\multicolumn{1}{c}{Method} & Accuracy      & Robustness    \\ \midrule
AVP                        & 34.4          & 13.1          \\
APT-UC                        & \textbf{54.9} & 24.8          \\
APT-UC + AVP                    & 54.2          & \textbf{25.3} \\ \bottomrule
\end{tabular}
}
\vspace{-3.5mm}
\end{table}

\vspace{-2mm}
%%%%%%%%% REFERENCES
{
    \tiny
    \bibliographystyle{ieeenat_fullname}
    \bibliography{references,reference}
}

\end{document}
